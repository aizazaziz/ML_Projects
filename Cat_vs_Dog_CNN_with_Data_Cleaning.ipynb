{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aizazaziz/ML_Projects/blob/main/Cat_vs_Dog_CNN_with_Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Helper Function to Clean Corrupted Images ---\n",
        "def check_and_clean_dataframe(df, image_col='images'):\n",
        "    \"\"\"\n",
        "    Iterates through image paths in the DataFrame, verifies image integrity\n",
        "    using PIL, and returns a DataFrame containing only valid image paths.\n",
        "    \"\"\"\n",
        "    valid_indices = []\n",
        "    invalid_count = 0\n",
        "\n",
        "    print(\"Starting robust image integrity check (This might take a few moments for large datasets)...\")\n",
        "\n",
        "    # Use iterrows to loop through the DataFrame rows\n",
        "    for index, row in df.iterrows():\n",
        "        filepath = row[image_col]\n",
        "\n",
        "        # Skip if the file doesn't exist (though it shouldn't, just for safety)\n",
        "        if not os.path.exists(filepath):\n",
        "            invalid_count += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Check for zero size\n",
        "            if os.path.getsize(filepath) == 0:\n",
        "                invalid_count += 1\n",
        "                continue\n",
        "\n",
        "            # Attempt to open and verify the image\n",
        "            img = Image.open(filepath)\n",
        "            img.verify()\n",
        "            img.close()\n",
        "            valid_indices.append(index)\n",
        "\n",
        "        except (UnidentifiedImageError, OSError, Exception) as e:\n",
        "            # Catch file corruption, truncated reads, or unidentified format errors\n",
        "            invalid_count += 1\n",
        "            # Optional: uncomment to see which files are being removed\n",
        "            # print(f\"Removed invalid file: {filepath} ({type(e).__name__})\")\n",
        "\n",
        "    if invalid_count > 0:\n",
        "        print(f\"\\n--- Data Cleaning Summary ---\")\n",
        "        print(f\"Total files originally listed: {len(df)}\")\n",
        "        print(f\"Total invalid/corrupt files removed: {invalid_count}\")\n",
        "        print(f\"Total valid files remaining: {len(valid_indices)}\")\n",
        "        print(\"-----------------------------\\n\")\n",
        "    else:\n",
        "        print(\"\\nIntegrity check complete: No corrupted files found.\")\n",
        "\n",
        "    return df.loc[valid_indices]\n",
        "\n",
        "\n",
        "# --- 1. Data Collection and DataFrame Creation ---\n",
        "image = []\n",
        "labels = []\n",
        "DATA_ROOT_DIR = \"ct\" # Base directory for Cat/Dog images\n",
        "\n",
        "# Build the list of image paths and labels\n",
        "for filename in os.listdir(DATA_ROOT_DIR):\n",
        "    current_dir_path = os.path.join(DATA_ROOT_DIR, filename)\n",
        "\n",
        "    if os.path.isdir(current_dir_path):\n",
        "        for path in os.listdir(current_dir_path):\n",
        "            full_path = os.path.join(current_dir_path, path)\n",
        "\n",
        "            # Ensure we are only listing files\n",
        "            if os.path.isfile(full_path):\n",
        "                # Assuming 'Cat' directory leads to label 0, and others (e.g., 'Dog') to 1\n",
        "                if filename == \"Cat\":\n",
        "                    labels.append(0)\n",
        "                else:\n",
        "                    labels.append(1)\n",
        "                image.append(full_path)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['images'] = image\n",
        "df['label'] = labels\n",
        "\n",
        "if image:\n",
        "    print(f\"Example Path: {df.iloc[0]['images']}, Example Label: {df.iloc[0]['label']}\")\n",
        "else:\n",
        "    print(f\"No images processed. Ensure '{DATA_ROOT_DIR}' directory and its subfolders exist and contain images.\")\n",
        "    exit() # Exit if no images are found\n",
        "\n",
        "# --- CRITICAL FIX: Clean Corrupted Files from the DataFrame ---\n",
        "df = check_and_clean_dataframe(df)\n",
        "\n",
        "# --- 2. Data Splitting and Preparation ---\n",
        "# Convert label to string for flow_from_dataframe\n",
        "df['label'] = df['label'].astype('str')\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train set size (validated): {len(train)}\")\n",
        "print(f\"Test set size (validated): {len(test)}\")\n",
        "\n",
        "# --- 3. ImageDataGenerator Setup ---\n",
        "TARGET_SIZE = (224, 224)\n",
        "\n",
        "# Data Augmentation for Training\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=20,\n",
        "                                   fill_mode='nearest',\n",
        "                                   zoom_range=0.2,\n",
        "                                   shear_range=0.2)\n",
        "\n",
        "# Only rescaling for Validation\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# Create Iterators\n",
        "train_iterator = train_datagen.flow_from_dataframe(train,\n",
        "                                                   x_col='images',\n",
        "                                                   y_col='label',\n",
        "                                                   target_size=TARGET_SIZE,\n",
        "                                                   class_mode='binary',\n",
        "                                                   batch_size=16,\n",
        "                                                   shuffle=True)\n",
        "\n",
        "val_iterator = val_datagen.flow_from_dataframe(test,\n",
        "                                               x_col='images',\n",
        "                                               y_col='label',\n",
        "                                               target_size=TARGET_SIZE,\n",
        "                                               class_mode='binary',\n",
        "                                               batch_size=16,\n",
        "                                               shuffle=True)\n",
        "\n",
        "\n",
        "# --- 4. CNN Model Definition ---\n",
        "# The UserWarning about input_shape is expected but harmless in Sequential model context\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(512, activation='relu'),\n",
        "    # Final output layer: 1 neuron with 'sigmoid' for binary classification\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# FIX APPLIED: Corrected loss function spelling from 'binary_cross_entropy' to 'binary_crossentropy'\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# --- 5. Model Training ---\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "\n",
        "# epochs were reduced to 5 in the previous run, keeping it at 5\n",
        "history = model.fit(train_iterator,\n",
        "                    epochs=5,\n",
        "                    validation_data=val_iterator,\n",
        "                    steps_per_epoch=len(train_iterator),\n",
        "                    validation_steps=len(val_iterator)\n",
        "                    )\n",
        "\n",
        "print(\"\\nTraining complete.\")\n",
        "\n",
        "# Optional: You can add code here to plot accuracy and loss over epochs."
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'ct'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-669775945.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Build the list of image paths and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mcurrent_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ct'"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BQYeP6gbFTuy",
        "outputId": "f2e0cca6-ca9e-433e-972e-abf2d9ad7a8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_SAVE_PATH = 'cat_dog_cnn_model.keras'\n",
        "TARGET_SIZE = (224, 224)\n",
        "CLASS_NAMES = {0: 'Cat', 1: 'Dog'}\n",
        "\n",
        "# --- Model Loading (Caching to load only once) ---\n",
        "# Streamlit caches this function's result, so the model loads quickly after the first run.\n",
        "@st.cache_resource\n",
        "def load_and_compile_model():\n",
        "    \"\"\"Loads the trained Keras model.\"\"\"\n",
        "    try:\n",
        "        model = load_model(MODEL_SAVE_PATH)\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading the model. Ensure '{MODEL_SAVE_PATH}' exists.\")\n",
        "        st.error(e)\n",
        "        return None\n",
        "\n",
        "# --- Prediction Function ---\n",
        "def predict_image(model, image_file):\n",
        "    \"\"\"\n",
        "    Loads, preprocesses, and makes a prediction on the uploaded image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load image from the uploaded file\n",
        "        img = Image.open(image_file).convert(\"RGB\")\n",
        "\n",
        "        # Display the uploaded image\n",
        "        st.image(img, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "        # Preprocess the image\n",
        "        img = img.resize(TARGET_SIZE)\n",
        "        img_array = np.array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0) # Add batch dimension (1, 224, 224, 3)\n",
        "        img_array = img_array.astype('float32') / 255.0 # Normalize (matching training)\n",
        "\n",
        "        # Make the prediction\n",
        "        prediction = model.predict(img_array)[0]\n",
        "        confidence = float(prediction[0])\n",
        "\n",
        "        # Determine the class and confidence\n",
        "        if confidence >= 0.5:\n",
        "            predicted_label = CLASS_NAMES[1]\n",
        "            confidence_score = confidence\n",
        "        else:\n",
        "            predicted_label = CLASS_NAMES[0]\n",
        "            # If the model predicts Cat (0), the confidence is 1 - prediction score\n",
        "            confidence_score = 1.0 - confidence\n",
        "\n",
        "        return predicted_label, confidence_score\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"An error occurred during prediction: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# --- Streamlit Main App Layout ---\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"Cat vs. Dog Classifier\", layout=\"centered\")\n",
        "\n",
        "    st.title(\"üê±üê∂ Simple Cat vs. Dog Image Classifier\")\n",
        "    st.markdown(\"Upload an image of a cat or a dog to see the model's prediction.\")\n",
        "\n",
        "    # Load the model\n",
        "    model = load_and_compile_model()\n",
        "\n",
        "    if model is None:\n",
        "        st.stop() # Stop the app if model loading failed\n",
        "\n",
        "    st.subheader(\"Upload an Image\")\n",
        "    uploaded_file = st.file_uploader(\"Choose an image file...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "\n",
        "        # Show a spinner while processing\n",
        "        with st.spinner('Analyzing image...'):\n",
        "            label, confidence = predict_image(model, uploaded_file)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        if label and confidence is not None:\n",
        "            # Display the result using Markdown for emphasis\n",
        "            st.success(f\"## Prediction: {label}\")\n",
        "\n",
        "            # Display confidence using a progress bar\n",
        "            st.write(f\"Confidence: **{confidence * 100:.2f}%**\")\n",
        "            st.progress(confidence)\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "sUAJmlQ0P0ly",
        "outputId": "77af3ebb-6935-418e-b695-08ba38b1c9ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-633806722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}